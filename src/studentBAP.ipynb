{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introduction:**\n",
    "In this project, we have a small dataset ( [from kaggle](https://kaggle.com)) of 1000 observations collected from students performances in three exams and their 5 features, some of these features are inherited, that means the student have no power to change any of them like gender ethnicity and parental level of eduction and other acquired feature like kind of lunch and test preparation.  \n",
    "In our analysis we try to find  corelation between the features level and the performance, and which features are the more importante, so may helps students improve their perfomance and /or take care of weak performance students.\n",
    "Although the dataset is quite clean, i did make some data clean up just for learning and practice purpose. \n",
    "In the analysis section i checked out the dataset balancing, data discription (statistical metrics), claculation of some sub dataset means and columns filtrering.   \n",
    "For the viusualisation i used pie chart to show the categorical features (gender and race/ethnicity) and bar plot for mean and  scores performances, Box plot for all features and all scores.\n",
    "In test module i used mannwhitneyu and scipy.stats libraries and run test upon some features that I have some doubt about them to confirm what we figure out from graphs.\n",
    "Finally i used Random Forest Classifier and Support Vector Machine  libraries to perfom somme predictions and to classify features importance.\n",
    "# *Note:*\n",
    "In order to use the main module from jupyter lab or google colab you should run all other cells before runing this main module.\n",
    "enjoy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Module:  \n",
    "This module perfomrs pre-analys work and prepares dataset and then ask the user what action he would like to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================\n",
      "|            StudentBAP             |\n",
      "|    Student Background Analysis    |\n",
      "|    Coppy right Kamel Haoua 2021   |\n",
      "|                                   |\n",
      "=====================================\n",
      "Initializing dataset...\n",
      "\n",
      "Reading dataset ok\n",
      "Process missing and or wrong values..\n",
      "--------------------------------------------------------\n",
      "Correcting columns names..\n",
      "Index(['gender', 'race_ethnicity', 'parental_level_of_education', 'lunch', 'test_preparation_course', 'math_score', 'reading_score', 'writing_score'], dtype='object')\n",
      "Replacing  wrong values with null..\n",
      "\n",
      "\n",
      "Collecting columns having a null values..\n",
      "column gender  data type object\n",
      "column race_ethnicity  data type object\n",
      "column parental_level_of_education  data type object\n",
      "column lunch  data type object\n",
      "column test_preparation_course  data type object\n",
      "column math_score  data type int64\n",
      "column reading_score  data type int64\n",
      "column writing_score  data type int64\n",
      "---------------------------------------------------------\n",
      "columns check finish, ok.\n",
      "Replacing numeric null values with mean\n",
      "Ok, replacement done\n",
      "Removing rows with null categorical values\n",
      "Ok,  Removing done\n",
      "\n",
      "\n",
      "File size: \n",
      "72036\n",
      "Dataset shape rows (count x comluns count):\n",
      "(1000, 8)\n",
      "\n",
      "Columns names:\n",
      "Index(['gender', 'race_ethnicity', 'parental_level_of_education', 'lunch', 'test_preparation_course', 'math_score', 'reading_score', 'writing_score'], dtype='object')\n",
      "\n",
      "Numeric columns:\n",
      "Index(['math_score', 'reading_score', 'writing_score'], dtype='object')\n",
      "\n",
      "Statistics:\n",
      "       math_score  reading_score  writing_score\n",
      "count  1000.00000    1000.000000    1000.000000\n",
      "mean     66.08900      69.169000      68.054000\n",
      "std      15.16308      14.600192      15.195657\n",
      "min       0.00000      17.000000      10.000000\n",
      "25%      57.00000      59.000000      57.750000\n",
      "50%      66.00000      70.000000      69.000000\n",
      "75%      77.00000      79.000000      79.000000\n",
      "max     100.00000     100.000000     100.000000\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Studentbap Main Module as command line interface\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os.path\n",
    "import numpy as np\n",
    "\"\"\"\"\n",
    "import analysisbap\n",
    "import graphicbap\n",
    "import mlbap\n",
    "import testbap\n",
    "\"\"\"\n",
    "pd.set_option('display.max_columns', 8)\n",
    "pd.set_option('display.width', 500)\n",
    "\n",
    "actions = ['analys','graph','test','ml']\n",
    "action = None\n",
    "ds = None\n",
    "dataset_path='data/StudentsPerformance.csv'\n",
    "env=get_ipython().__class__.__name__\n",
    "\"\"\"\n",
    "In order to run script from terminal we create this main method in each module\n",
    "\"\"\"\n",
    "def main() :\n",
    "    \n",
    "    print('=====================================')\n",
    "    for i in range(6) :\n",
    "        if i==3 :\n",
    "            print('|            StudentBAP             |')\n",
    "            print('|    Student Background Analysis    |')\n",
    "            print('|    Coppy right Kamel Haoua 2021   |')\n",
    "            print('|                                   |')\n",
    "    print('=====================================')\n",
    "    print('Initializing dataset...')\n",
    "    print()\n",
    "    load_dataset()\n",
    "    cleanup_dataset(num_columns = ds[['math score','reading score','writing score']].columns)\n",
    "    datasetInfos()\n",
    "    if env != 'TerminalInteractiveShell' : # if executed from notebook don't ask user for actions\n",
    "        return\n",
    "    \n",
    "    action = get_user_action()\n",
    "    if ((action == None) or (len(action) == 0)):\n",
    "        print('Sorry i can\\'t understand your action,! see you next time.')\n",
    "        exit()\n",
    "    elif action == 'exit':\n",
    "        return\n",
    "    else:\n",
    "        execute_action(action)\n",
    "\"\"\"\n",
    "Load dataset from path (data/StudentsPerformance.csv)\n",
    "if file path not exists it stops the execution of script\n",
    "\"\"\"        \n",
    "def load_dataset():\n",
    "    global ds\n",
    "    if (os.path.exists(dataset_path)):\n",
    "        ds = pd.read_csv(dataset_path)\n",
    "        print('Reading dataset ok')\n",
    "    else:\n",
    "        print('file '+dataset_path+' doesn\\'t exits. Please check file system and try agin later.' )    \n",
    "        return\n",
    "\n",
    "#display help how to use scripts\n",
    "def show_help():\n",
    "    print('usage :\\n'+ \\\n",
    "    'action \\n'+ \\\n",
    "    '\\n'+ \\\n",
    "    'Where action is one of the following:\\n'+ \\\n",
    "    'analys: perfom all statistical analysis.\\n'+ \\\n",
    "    'graph: display graphics and plots\\n'+ \\\n",
    "    'test: run statistical tests\\n'+ \\\n",
    "    'ml: make a prediction and show features importance classification\\n'+ \\\n",
    "    'exit: stop script\\n')\n",
    "    \n",
    "#Prompts user for action he wants to perfom and return user std input text\n",
    "def get_user_action():\n",
    "    print('Type help or any action.?')\n",
    "    print()\n",
    "    maxtry=3;\n",
    "    while(maxtry>0):\n",
    "        action = input(\"action: \")\n",
    "        if ((action is None) or len(action) == 0 ):\n",
    "            print ('No action specified!. type help or shoose one action: \\n'+', '.join(actions))\n",
    "            print()\n",
    "        elif ((action in actions) or (action == 'exit')) :\n",
    "            return action;\n",
    "        elif action == 'help' :\n",
    "            show_help() \n",
    "        else:\n",
    "            print('Unknown action. \"'+action+'\"\\n'+'type help or choose one action: \\n'+', '.join(actions))\n",
    "            print()\n",
    "        if maxtry == 0 :\n",
    "            return None;\n",
    "        else:\n",
    "            maxtry-=1;\n",
    "                \n",
    "#Execute initiation methods and execute one action                \n",
    "def execute_action(act=None):\n",
    "    \n",
    "    if(act=='exit') :\n",
    "        print('stoping script... good bye.')\n",
    "        return  \n",
    "    else :  \n",
    "        print('executing action: '+str(act)+'\\nPlease wait this action may take a while... ')\n",
    "        if env == 'TerminalInteractiveShell' : # execution from terminal we call secripts main method\n",
    "            if act=='analys' :\n",
    "                analysbap.main()\n",
    "            elif act=='graph' :\n",
    "                graphicbap.main() \n",
    "            elif act=='test' :\n",
    "                testbap.main() \n",
    "            elif act=='ml' :\n",
    "                mlbap.main()\n",
    "            else:\n",
    "                print('Unknown action: ('+str(act)+')')    \n",
    "        else : # execution from notebook we call methods in this notebook\n",
    "            if act=='analys' :\n",
    "                check_data_balancing('gender')\n",
    "                check_data_balancing('race_ethnicity')\n",
    "                analysis()\n",
    "            elif act=='graph' :\n",
    "                select_graph() \n",
    "            elif act=='test' :\n",
    "                run_all_tests()\n",
    "            elif act=='ml' :\n",
    "                init_ml()\n",
    "                start_ml()\n",
    "            else:\n",
    "                print('Unknown action: ('+str(act)+')')\n",
    "            \n",
    "\n",
    "# verify dataset\n",
    "\n",
    "\"\"\"\n",
    " if there is a missing or wrong values we have to process each column depending on its data type\n",
    " if data type is not numeric we remove the row from dataset, if is nemuric we replace\n",
    " non conform values with NaN and replace NaN values with the mean of that column\n",
    "\"\"\"\n",
    "def cleanup_dataset(num_columns=None) :\n",
    "    print('Process missing and or wrong values..')\n",
    "    print('--------------------------------------------------------')\n",
    "    \n",
    "    #some column names contain white-space and back slash character, \n",
    "    #so we have to replace it with underscore character(_).\n",
    "\n",
    "    print('Correcting columns names..')\n",
    "    ds.columns=ds.columns.str.replace(' ','_')\n",
    "    ds.columns=ds.columns.str.replace('\\/','_')\n",
    "    columns= ds.columns\n",
    "\n",
    "    print(columns)\n",
    "    print('Replacing  wrong values with null..')\n",
    "    if(num_columns is None):\n",
    "        num_columns=ds.select_dtypes(include='int64')\n",
    "        print()\n",
    "                \n",
    "        for nc in num_columns :\n",
    "            ds[nc]=ds[nc].apply(lambda x : np.nan if str(type(x))==\"<class 'str'>\" else x)\n",
    "    print('\\n')\n",
    "    print('Collecting columns having a null values..')  \n",
    "\n",
    "    column_with_null_value=list()\n",
    "    \n",
    "    for column in columns :\n",
    "        datatype=ds[column].dtype\n",
    "        print('column '+column+'  data type '+str(datatype))\n",
    "        if (ds[column].isnull().values.any==True):\n",
    "            column_with_null_value.append(column)   \n",
    "    print('---------------------------------------------------------')\n",
    "    \n",
    "    if len(column_with_null_value)==0:\n",
    "        print('columns check finish, ok.')\n",
    "    else :\n",
    "        print('some columns have null values\\n')\n",
    "        print(column_with_null_value)   \n",
    "    print('Replacing numeric null values with mean')\n",
    "    replcement_values={}\n",
    "    if(len(column_with_null_value)>0) :\n",
    "        for c in column_with_null_value :\n",
    "            if(c in num_columns) :\n",
    "                meanvalue=ds[c].mean(skipna=True)\n",
    "                replcementValues[c]=meanvalue\n",
    "    ds.fillna(value=replcement_values, inplace=True)\n",
    "    print('Ok, replacement done')\n",
    "    print('Removing rows with null categorical values')\n",
    "    ds.dropna(inplace=True)\n",
    "    print('Ok,  Removing done')\n",
    "    print('\\n')\n",
    "\n",
    "\"\"\"\n",
    "Dataset discritption\n",
    "\"\"\"\n",
    "def datasetInfos() :\n",
    "    if(os.path.exists(dataset_path)) :\n",
    "        print('File size: ')\n",
    "        print(os.stat(dataset_path).st_size)\n",
    "    if ds is None :\n",
    "        print('No data available yet !.')\n",
    "        exit()\n",
    "    else :    \n",
    "        print('Dataset shape rows (count x comluns count):')\n",
    "        print(ds.shape)\n",
    "        print()\n",
    "        print('Columns names:')\n",
    "        print(ds.columns)\n",
    "        print()\n",
    "        print('Numeric columns:')\n",
    "        print(ds.select_dtypes(include='int64').columns)\n",
    "        print()\n",
    "        print('Statistics:')\n",
    "        print(ds.describe())\n",
    "\n",
    "#execute the main program\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nrofLu_y0_Db"
   },
   "source": [
    "# Analysis:\r\n",
    "* Data balancing check:  \r\n",
    "check if the data is balanced:\r\n",
    "In this dataset we have two columns gender and race/ethnicity that are\r\n",
    "categorical variable, they should have the same number of values for each category (eg. 500 men and 500 women) or not less than 90% and not greater than 10% of normal count (normal_count equals total observations divided by unique values )\r\n",
    "\r\n",
    "* Data analysis:  \r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Module analys perfoms statistical Analysis\n",
    "\"\"\"\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "def main():\n",
    "    check_data_balancing('gender')\n",
    "    check_data_balancing('race_ethnicity')\n",
    "    analysis()\n",
    "    \n",
    "def check_data_balancing(cat_column=None) :\n",
    "    print('Data balancing check for column '+cat_column)\n",
    "    print()\n",
    "    if cat_column  is None :\n",
    "        print('None categorical column')\n",
    "        pass\n",
    "    \n",
    "    unique_count = ds[cat_column].nunique()\n",
    "    ds_size = ds[cat_column].size\n",
    "    grouped_ds=ds.groupby(by=cat_column)\n",
    "    normal_count=ds_size/unique_count\n",
    "    print('Normal count for column '+cat_column+' = '+str(normal_count))\n",
    "    real_count=grouped_ds.size()\n",
    "    print('values count in each category '+cat_column)\n",
    "    print(real_count.to_string())\n",
    "    is_balanced=True\n",
    "    \n",
    "    for count in real_count :\n",
    "        ratio = count / normal_count\n",
    "        if (count / normal_count) > 1.1 :\n",
    "            is_balanced=False\n",
    "            break\n",
    "           \n",
    "    if is_balanced:\n",
    "         print('Sample for category '+cat_column+' is balanced')\n",
    "    else:\n",
    "         print('Sample for category '+cat_column+' is not balanced, ' \\\n",
    "               +'because some group contain more than 90% of the total values of culumn '+cat_column)\n",
    "    print('---------------------------------------------------')\n",
    "    \n",
    "def analysis():\n",
    "    print('Data analysis')\n",
    "    if ds is None:\n",
    "        print('Dataset no available')\n",
    "        return\n",
    "    else:\n",
    "       \n",
    "        print('Find min / max values')\n",
    "        print()\n",
    "        print('Student''s gender who get <= 20% math score')\n",
    "        ds_less_20=ds[ds['math_score']<=20][['gender','race_ethnicity']] \\\n",
    "              .groupby(by=['race_ethnicity','gender']).size()\n",
    "        print(pd.DataFrame({'count':ds_less_20}).reset_index())\n",
    "        print()\n",
    "        print('Student''s gender who get >=80% math score')\n",
    "        ds_greater_80=ds[ds['math_score']>=80][['gender','race_ethnicity']]\\\n",
    "              .groupby(by=['race_ethnicity','gender']).size()\n",
    "        print(pd.DataFrame({'count':ds_greater_80}).reset_index())\n",
    "        print()\n",
    "                \n",
    "        print('Dataset discription:')\n",
    "        print(ds.describe())\n",
    "        print()    \n",
    "        print('Calculating means for each feature...')\n",
    "        print()\n",
    "        print('Mean by gender')\n",
    "        print(ds.groupby(ds['gender']).mean())\n",
    "        print()\n",
    "        print('Mean by race/ethnicity')\n",
    "        print(ds.groupby(ds['race_ethnicity']).mean())\n",
    "        print()\n",
    "        print('Mean by parental level of eductaion')\n",
    "        print(ds.groupby(ds['parental_level_of_education']).mean())\n",
    "        print()\n",
    "        print('Mean by lunch')\n",
    "        print(ds.groupby(ds['lunch']).mean())\n",
    "        print()\n",
    "        print('Mean by test preparation course')\n",
    "        print(ds.groupby(ds['test_preparation_course']).mean())\n",
    "        print('--------------------------------------------------')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGNe4ZIq5s-J"
   },
   "source": [
    "# **Analys reuslts**\r\n",
    "* Data balancing:  \r\n",
    "The column race/ethnicity holds  5 groups of students and the number in each group is sginficantely far from normal number that is 200 , thus we don't expect an accurate results later in prediction and classification because they affect the mean and the varaince as well.\r\n",
    "* Analysis:  \r\n",
    "1. We see some outlier values like 0, but they are not due \r\n",
    "to mistakes because they are also equivalent in all scores, so these values could affect the mean because there are only three values below score 20 in math exam, removing these values could yield more accurate results.\r\n",
    "2. Females are good in writing and reading but males are good than females in math.\r\n",
    "3. There are some diffrence between groups of races the best one is gruop E and the weak one is group A in all scores.\r\n",
    "4. Students who toke a standard lunch have better performance than other.\r\n",
    "5. Test preparation course  also made difference.  \r\n",
    "\r\n",
    "**Note:**  \r\n",
    "These findings are based only on means, so we have to see what is the in graphs for better unsersanding what really make a diffrence. \r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wr8Wb4U11I2K"
   },
   "source": [
    "# **Graphics**\r\n",
    "*   **Categorical variables:**  \r\n",
    "We have a two principal categorical features, gender and race/ethnicity, in this plot we could see how the dataset is blanaced, that mean if we have nearly equivalents numbers of each category.\r\n",
    "*   **Extrem Scores:**  \r\n",
    "Above 80 and under 20 scores to find out how much extrem values we have and understand if they affectting  the mean for categorical values.\r\n",
    "*   **Mean Graph**  \r\n",
    "Mean score for each feature could give us an idea about if there some diffrence between categories regarding the given feature  \r\n",
    "*   **Box Graph:**\r\n",
    "To show some metrics variables like max, min, outliers, median and variance for each feature and each scores.  \r\n",
    " \r\n",
    "*  **All score for each features:**  \r\n",
    "This graph show all scores grouped by each features.\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Module graphics\n",
    "\"\"\"\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "#plt.rcParams[\"figure.figsize\"] = [16, 16]\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "def main():\n",
    "    select_graph()\n",
    "      \n",
    "def select_graph():\n",
    "    #ask user which graph or print pass\n",
    "    print('Graphic module')\n",
    "    choice=input('Please make a choice:\\n' \\\n",
    "              +'Enter 1 for categorical variables\\n' \\\n",
    "              +'Enter 2 for extrem scores\\n' \\\n",
    "              +'Enter 3 for Mean graph\\n' \\\n",
    "              +'Enter 4 for box graph\\n' \\\n",
    "              +'Enter 5 for all score for each feature\\n' \\\n",
    "              +'Press enter key to cancel\\n' )\n",
    "  \n",
    "    if (not choice):\n",
    "        return\n",
    "    else:\n",
    "        if (choice=='1'):\n",
    "            categorical_variables()\n",
    "        elif (choice=='2') :\n",
    "            extreme_scores()\n",
    "        elif (choice=='3') :\n",
    "            mean_graph()\n",
    "        elif (choice=='4') :\n",
    "            box_graphs()\n",
    "        elif (choice=='5') :      \n",
    "            allscores_for_ech_feature()\n",
    "        else: \n",
    "            return\n",
    "    \n",
    "def categorical_variables():\n",
    "    # 1) Categorical variables distribution\n",
    "    #Gender \n",
    "    genders= ds.gender.value_counts().to_dict()\n",
    "    races= pd.DataFrame(sorted(ds.race_ethnicity.value_counts().to_dict().items()), columns=['race_ethnicity','count'])\n",
    "    \n",
    "    #print(pd.DataFrame(sorted(races.items()), columns=['races','count']))\n",
    "    #print(pd.DataFrame({'count':ds.race_ethnicity.value_counts()}).reset_index().sort_values(['index']))\n",
    "\n",
    "    fig, ax=  plt.subplots(nrows=1,ncols=2, figsize=[12,6])\n",
    "        \n",
    "    ax[0].pie(x=genders.values(),data=genders, labels=['']* len(genders.keys()),colors=['hotpink','blue'], autopct='%1.1f%%')\n",
    "    ax[0].axis('equal')\n",
    "    ax[0].set_title('Gender')\n",
    "    ax[0].legend(genders.keys())\n",
    "    \n",
    "    #Race/Ethnicity\n",
    "    ax[1].pie(x=(races['count']),data=(races), labels=['']* len(races.race_ethnicity), autopct='%1.1f%%', counterclock=False)\n",
    "    ax[1].axis('equal')\n",
    "    ax[1].set_title('Races/Ethnicity')\n",
    "    ax[1].legend(races['race_ethnicity'])\n",
    "    \n",
    "    fig.patch.set_facecolor('white')\n",
    "    fig.suptitle('Categorical variables distribution',fontsize=16)\n",
    "    fig.subplots_adjust(top=0.88)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    print('------------------------------------------------------------------------')\n",
    "    \n",
    "def extreme_scores():\n",
    "    fig, ax=  plt.subplots(nrows=3,ncols=2, sharey=False, figsize=[16,16])\n",
    "    fig.suptitle('Extreme scores grouped by races and then by gender', fontsize=16)\n",
    "    # math score\n",
    "    #------------------------------------------------------------------------------------\n",
    "    math_less_20=ds.loc[ds['math_score']<=20].reindex(columns=['gender','race_ethnicity'])\\\n",
    "              .groupby(by=['race_ethnicity','gender']).size()\n",
    "    math_df_20=pd.DataFrame({'counts':math_less_20}).reset_index()\n",
    "    sns.barplot(ax=ax[0,0],palette=['hotpink','blue'], data=math_df_20, x='race_ethnicity', y='counts',hue='gender')\n",
    "    ax[0,0].set_title('Under 20 math score')\n",
    "    \n",
    "    math_greater_80=ds.loc[ds['math_score']>=80].reindex(columns=['gender','race_ethnicity'])\\\n",
    "              .groupby(by=['race_ethnicity','gender']).size()\n",
    "    math_df_80=pd.DataFrame({'counts':math_greater_80}).reset_index()\n",
    "    sns.barplot(ax=ax[0,1],palette=['hotpink','blue'], data=math_df_80, x='race_ethnicity', y='counts',hue='gender')\n",
    "    ax[0,1].set_title('Above 80 math score')\n",
    "    \n",
    "    # reding score\n",
    "    #--------------------------------------------------------------------------------\n",
    "    read_less_20=ds.loc[ds['reading_score']<=20].reindex(columns=['gender','race_ethnicity'])\\\n",
    "              .groupby(by=['race_ethnicity','gender']).size()\n",
    "    read_df_20=pd.DataFrame({'counts':read_less_20}).reset_index()\n",
    "    sns.barplot(ax=ax[1,0],palette=['hotpink','blue'], data=read_df_20, x='race_ethnicity', y='counts',hue='gender')\n",
    "    ax[1,0].set_title('Under 20 reading score')\n",
    "    \n",
    "    read_greater_80=ds.loc[ds['reading_score']>=80].reindex(columns=['gender','race_ethnicity'])\\\n",
    "              .groupby(by=['race_ethnicity','gender']).size()\n",
    "    read_df_80=pd.DataFrame({'counts':read_greater_80}).reset_index()\n",
    "    sns.barplot(ax=ax[1,1],palette=['hotpink','blue'], data=read_df_80, x='race_ethnicity', y='counts',hue='gender')\n",
    "    ax[1,1].set_title('Above 80 reading score')    \n",
    "    #--------------------------------------------------------------------------------\n",
    "    # writing score\n",
    "    \n",
    "    write_less_20=ds.loc[ds['writing_score']<=20].reindex(columns=['gender','race_ethnicity'])\\\n",
    "              .groupby(by=['race_ethnicity','gender']).size()\n",
    "    write_df_20=pd.DataFrame({'counts':write_less_20}).reset_index()\n",
    "    sns.barplot(ax=ax[2,0],palette=['hotpink','blue'], data=write_df_20, x='race_ethnicity', y='counts',hue='gender')\n",
    "    ax[2,0].set_title('Under 20 writing score')\n",
    "    \n",
    "    write_greater_80=ds.loc[ds['writing_score']>=80].reindex(columns=['gender','race_ethnicity'])\\\n",
    "              .groupby(by=['race_ethnicity','gender']).size()\n",
    "    write_df_80=pd.DataFrame({'counts':write_greater_80}).reset_index()\n",
    "    sns.barplot(ax=ax[2,1],palette=['hotpink','blue'], data=write_df_80, x='race_ethnicity', y='counts', hue='gender')\n",
    "    ax[2,1].set_title('Above 80 writing score')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def mean_graph():\n",
    "    fig, ax = plt.subplots(nrows=3,ncols=2, sharey=False, figsize=[25,25])\n",
    "    ax[-1, -1].axis('off')\n",
    "    fig.suptitle('Means grouped by categorical variables', fontsize=16)\n",
    "        \n",
    "    by_gender= ds.groupby(ds['gender']).mean().reset_index()\n",
    "    by_gender=by_gender.melt('gender',var_name='means',value_name='score_means')\n",
    "    sns.barplot(ax=ax[0,0], data=by_gender, x='gender', y='score_means',hue='means')\n",
    "    ax[0,0].set_title('mean by gender')\n",
    "        \n",
    "    by_race= ds.groupby(ds['race_ethnicity']).mean().reset_index()\n",
    "    by_race=by_race.melt('race_ethnicity',var_name='means',value_name='score_means')\n",
    "    sns.barplot(ax=ax[0,1], data=by_race, x='race_ethnicity', y='score_means',hue='means')\n",
    "    ax[0,1].set_title('mean by race_ethnicity')\n",
    "        \n",
    "    by_ple=ds.groupby(ds['parental_level_of_education']).mean().reset_index()\n",
    "    by_ple=by_ple.melt('parental_level_of_education',var_name='means',value_name='score_means')\n",
    "    sns.barplot(ax=ax[1,0], data=by_ple, x='parental_level_of_education', y='score_means',hue='means')\n",
    "    ax[1,0].set_title('mean by parental_level_of_education') \n",
    "    ax[1,0].set_xticklabels(ax[1,0].get_xticklabels(), rotation=15)   \n",
    "       \n",
    "    by_lunch=ds.groupby(ds['lunch']).mean().reset_index()\n",
    "    by_lunch=by_lunch.melt('lunch',var_name='means',value_name='score_means')\n",
    "    sns.barplot(ax=ax[1,1], data=by_lunch, x='lunch', y='score_means',hue='means')\n",
    "    ax[1,1].set_title('Mean by lunch type')    \n",
    "       \n",
    "    by_tpc=ds.groupby(ds['test_preparation_course']).mean().reset_index()\n",
    "    by_tpc=by_tpc.melt('test_preparation_course',var_name='means',value_name='score_means')\n",
    "    sns.barplot(ax=ax[2,0], data=by_tpc, x='test_preparation_course', y='score_means',hue='means')\n",
    "    ax[2,0].set_title('Mean by test_preparation_course') \n",
    "    #plt.tight_layout()\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "def box_graphs():\n",
    "    fig, ax = plt.subplots(nrows=5, ncols=3, figsize=[40,40])\n",
    "    fig.suptitle('Grouped by features and scores', fontsize=16)\n",
    "        \n",
    "    sns.boxplot(ax=ax[0,0],y='gender',x='math_score', data=ds, palette=['hotpink','blue'])\n",
    "    sns.boxplot(ax=ax[0,1],y='gender',x='reading_score', data=ds, palette=['hotpink','blue'])\n",
    "    sns.boxplot(ax=ax[0,2],y='gender',x='writing_score', data=ds, palette=['hotpink','blue'])\n",
    "    \n",
    "    sns.boxplot(ax=ax[1,0],y='race_ethnicity',x='math_score', data=ds)\n",
    "    sns.boxplot(ax=ax[1,1],y='race_ethnicity',x='reading_score', data=ds)\n",
    "    sns.boxplot(ax=ax[1,2],y='race_ethnicity',x='writing_score', data=ds)\n",
    "    \n",
    "    sns.boxplot(ax=ax[2,0],y='parental_level_of_education',x='math_score', data=ds)\n",
    "    sns.boxplot(ax=ax[2,1],y='parental_level_of_education',x='reading_score', data=ds)\n",
    "    sns.boxplot(ax=ax[2,2],y='parental_level_of_education',x='writing_score', data=ds)\n",
    "    \n",
    "    sns.boxplot(ax=ax[3,0],y='lunch',x='math_score', data=ds)\n",
    "    sns.boxplot(ax=ax[3,1],y='lunch',x='reading_score', data=ds)\n",
    "    sns.boxplot(ax=ax[3,2],y='lunch',x='writing_score', data=ds)\n",
    "    \n",
    "    sns.boxplot(ax=ax[4,0],y='test_preparation_course',x='math_score', data=ds)\n",
    "    sns.boxplot(ax=ax[4,1],y='test_preparation_course',x='reading_score', data=ds)\n",
    "    sns.boxplot(ax=ax[4,2],y='test_preparation_course',x='writing_score', data=ds)\n",
    "    \n",
    "    \n",
    "    plt.show() \n",
    "    \n",
    "def all_scores_for_each_feature():\n",
    "    fig, ax = plt.subplots(nrows=5, ncols=4, figsize=[40,40])\n",
    "    plt.xticks(rotation=45)\n",
    "    fig.suptitle('Mean and scores of three exams', fontsize=28)\n",
    "    \n",
    "    # Mean\n",
    "    mean_perormance=ds.eval('(math_score + reading_score + writing_score)/3').rename('mean_perormance')\n",
    "    sns.barplot(ax=ax[0,0], data=ds,y=mean_perormance , x='gender',palette=['hotpink','blue']).set_title('Mean for all scores', fontsize=18)\n",
    "    sns.barplot(ax=ax[1,0], data=ds,y=mean_perormance , x='race_ethnicity')\n",
    "    ple=sns.barplot(ax=ax[2,0], data=ds,y=mean_perormance , x='parental_level_of_education')\n",
    "    ple.set_xticklabels(ple.get_xticklabels(),rotation=20)\n",
    "    \n",
    "    sns.barplot(ax=ax[3,0], data=ds,y=mean_perormance , x='lunch')\n",
    "    sns.barplot(ax=ax[4,0], data=ds,y=mean_perormance , x='test_preparation_course')\n",
    "   \n",
    "    # Math score\n",
    "    sns.barplot(ax=ax[0,1], data=ds,y='math_score' , x='gender',palette=['hotpink','blue']).set_title('Math score', fontsize=18)\n",
    "    sns.barplot(ax=ax[1,1], data=ds,y='math_score' , x='race_ethnicity')\n",
    "    sns.barplot(ax=ax[2,1], data=ds,y='math_score' , x='parental_level_of_education').set_xticklabels(ple.get_xticklabels(),rotation=30)\n",
    "    sns.barplot(ax=ax[3,1], data=ds,y='math_score' , x='lunch')\n",
    "    sns.barplot(ax=ax[4,1], data=ds,y='math_score' , x='test_preparation_course')\n",
    "    \n",
    "    # Reading score\n",
    "    sns.barplot(ax=ax[0,2], data=ds,y='reading_score' , x='gender',palette=['hotpink','blue']).set_title('Reading score', fontsize=18)\n",
    "    sns.barplot(ax=ax[1,2], data=ds,y='reading_score' , x='race_ethnicity')\n",
    "    sns.barplot(ax=ax[2,2], data=ds,y='reading_score' , x='parental_level_of_education').set_xticklabels(ple.get_xticklabels(),rotation=30)\n",
    "    sns.barplot(ax=ax[3,2], data=ds,y='reading_score' , x='lunch')\n",
    "    sns.barplot(ax=ax[4,2], data=ds,y='reading_score' , x='test_preparation_course')\n",
    "    \n",
    "    # Writing scores\n",
    "    sns.barplot(ax=ax[0,3], data=ds,y='writing_score' , x='gender',palette=['hotpink','blue']).set_title('Writing scores', fontsize=18)\n",
    "    sns.barplot(ax=ax[1,3], data=ds,y='writing_score' , x='race_ethnicity')\n",
    "    sns.barplot(ax=ax[2,3], data=ds,y='writing_score' , x='parental_level_of_education').set_xticklabels(ple.get_xticklabels(),rotation=30)\n",
    "    sns.barplot(ax=ax[3,3], data=ds,y='writing_score' , x='lunch')\n",
    "    sns.barplot(ax=ax[4,3], data=ds,y='writing_score' , x='test_preparation_course')\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    main()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Graphs Results:**  \n",
    "1. Categorical graph distribution:  \n",
    "This graph show that data in gender feature is balanced, however in the race ethnicity feature is not.  \n",
    "2. Extrem scores graph:  \n",
    "This graph  shows our hypotesis about gender feature but not for race feature,it say that males are better than females in math and vis versa. but for race/ethnicity we found in our previous group E is better than all others but here it isn't.\n",
    "3. Mean graph:  \n",
    "* By gender: it shows our hypotesis, Male are better than females in math and females are better than males in other perfomances.\n",
    "* Race / Ethnicity: it shows that there is a preponderance between all groups, the race E is better than others and group A is the weakest one.\n",
    "* Parental level of educaction: There is some preponderance between all levels for reading and writing , the master degree is the best one and high school is the weakest one, however there is some simillarties in math in (master degree vs bachelor degree) and (some college vs associate degree), may be due to other factors like lunch or test preparation corse or race ethnicity. \n",
    "We somehow understand that the PLO is a bit relevant for students perfomance, so the parents may give some academic help or due to genetic inhertance.\n",
    "although what we  we have to run some statistical test to clarify the relationship existnece.\n",
    "* Lunch: the difference is about 10%, the standard lunch may increase performance in all scores.\n",
    "* Test preparation course : the same as lunch but math score is about less than 10% diff.\n",
    "4. Box graphs:  \n",
    "This graph show us some metrical data like min, max  are the first and last vertical lines, outliers point outside the graph, median the vertical line inside the box also 50th percentile or 2nd quartile Q2, first quartile Q1 or 25% and third quartile Q3 or 75% are the  boxe's limites, if the median line is not close to the midle of the box that means the sample is not normal distribution, more the box is longer more the data variability is bigger. \n",
    "Interquartile range IQO is the box length or Q3 - Q 1.\n",
    "This graph excludes outliers data points so it may correcte some weakness of mean beause this one is much affected by the outliers.\n",
    "\n",
    "* Genders: the difference in math is not really signifcante about 5% or less, but in other scores it is clear that females are much better than males, however we have to examine these outliers values if not comes from mistakes.\n",
    "* race/ethnicity: group E is the best in math with a bit difference in reading, while group A the weakest one in all scores.\n",
    "* parental level of education: \n",
    "we could distinguishe two groups in math, first group are\n",
    "High school and some high school are a bit simillar and it is the weakest group and second group is all others, how ever in reading and writing we could distinguish two groups in the second group the master degree and bachelor degree are the best ones.  \n",
    "Although we could distinguish groups, the deiffreneces are not signifcante because of variability of scores.\n",
    "* Lunch and test preparation course have  a clear difference. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  **Test statistic:** \n",
    "* Two-Way test  \n",
    "This test takes two samples and compares their means and checks if they are significantelly different.  \n",
    "Given an aplha value = 5%  of the sample as signifcance level and two-sided alternative , that means we test a possibility of corelation between a feature  level x and the label or target calss y in both directions, 2.5% each side  (less then and greater than 2.5%).  \n",
    "If the test yields a p-value less than 0.05 we confirm the existance of the corelation or alternative hypothesis (Ha).\n",
    "* One-Ways test:  \n",
    "The main difference between the first one and this one is that this can take more than two samples or groups. If only one group is distinguishable from others the test passes or null hypothesis  will be rejected.\n",
    "This test also could can take multiples input and produce test result (F,P) for each.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Running tests for each categorical variable:\n",
    "We try to find out if there is a correlation between a given category of students\n",
    "and any of the performances, so we have to filter out a category and compare them \n",
    "against each another.\n",
    "\"\"\"\n",
    "from scipy.stats import mannwhitneyu\n",
    "import scipy.stats as stats\n",
    "def main():\n",
    "    run_all_tests()\n",
    "    \n",
    "def run_2ways_test(dist1,dist2):\n",
    "    alpha = 0.05\n",
    "    stat,pv = mannwhitneyu(dist1,dist2,alternative='two-sided')\n",
    "    return pv < alpha\n",
    "    \n",
    "def run_all_tests():\n",
    "    principal_columns=['math_score','reading_score','writing_score']\n",
    "    \n",
    "    males=ds[ds['gender']=='male'][principal_columns]\n",
    "    females=ds[ds['gender']=='female'][principal_columns]   \n",
    "    \n",
    "    group_a=ds[ds['race_ethnicity']=='group A'][principal_columns]\n",
    "    group_b=ds[ds['race_ethnicity']=='group B'][principal_columns]\n",
    "    group_c=ds[ds['race_ethnicity']=='group C'][principal_columns]\n",
    "    group_d=ds[ds['race_ethnicity']=='group D'][principal_columns]\n",
    "    group_e=ds[ds['race_ethnicity']=='group E'][principal_columns]\n",
    "    \n",
    "    bachelor_degree=ds[ds['parental_level_of_education']=='bachelor''s degree'][principal_columns]\n",
    "    master_degree=ds[ds['parental_level_of_education']=='master''s degree'][principal_columns]\n",
    "    ass_degree=ds[ds['parental_level_of_education']=='associate''s degree'][principal_columns]\n",
    "    somme_college=ds[ds['parental_level_of_education']=='some college'][principal_columns]\n",
    "    high_school=ds[ds['parental_level_of_education']=='high school'][principal_columns]\n",
    "    somme_high_school=ds[ds['parental_level_of_education']=='some high school'][principal_columns]\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('---------Running  two-ways test:----------')\n",
    "    print()\n",
    "    print('---------Gender test:----------')\n",
    "    print()\n",
    "    math_test=run_2ways_test(males['math_score'],females['math_score'])\n",
    "    writing_test=run_2ways_test(males['reading_score'],females['reading_score'])\n",
    "    redaing_test=run_2ways_test(males['writing_score'],females['writing_score'])\n",
    "    \n",
    "    print('Male are '+('good than 'if math_test else 'equal with'  )+'females in math ')\n",
    "    print('Females are '+('good than 'if writing_test else 'equal with '  )+'males in writing ')\n",
    "    print('Females are '+('good than 'if redaing_test else 'equal with '  )+'males in reading ')\n",
    "        \n",
    "    print()\n",
    "    print('---------Race/Ethnicity ---------')\n",
    "    print()\n",
    "    math_test=run_2ways_test(group_e['math_score'],group_d['math_score'])\n",
    "    writing_test=run_2ways_test(group_e['reading_score'],group_d['reading_score'])\n",
    "    redaing_test=run_2ways_test(group_e['writing_score'],group_d['writing_score'])\n",
    "    \n",
    "    print('Group E vs group D:')\n",
    "    \n",
    "    print('group E is '+('good than 'if math_test else 'similar with'  )+'group D in math ')\n",
    "    print('group E is '+('good than 'if writing_test else 'similar with '  )+'group D in writing ')\n",
    "    print('group E is '+('good than 'if redaing_test else 'similar with '  )+'group D in reading ') \n",
    "    print()\n",
    "    print('Group D vs group C:')\n",
    "    math_test=run_2ways_test(group_d['math_score'],group_c['math_score'])\n",
    "    writing_test=run_2ways_test(group_d['reading_score'],group_c['reading_score'])\n",
    "    redaing_test=run_2ways_test(group_d['writing_score'],group_c['writing_score'])\n",
    "    \n",
    "    print('group D is '+('good than 'if math_test else 'similar with'  )+'group C in math ')\n",
    "    print('group D is '+('good than 'if writing_test else 'similar with '  )+'group C in writing ')\n",
    "    print('group D is '+('good than 'if redaing_test else 'similar with '  )+'group C in reading ')\n",
    "    print()\n",
    "    print('---------Parental level of education test ---------')\n",
    "    print()\n",
    "   \n",
    "    print('bachelor degree vs master degree:')\n",
    "    math_test=run_2ways_test(bachelor_degree['math_score'],master_degree['math_score'])\n",
    "    writing_test=run_2ways_test(bachelor_degree['reading_score'],master_degree['reading_score'])\n",
    "    redaing_test=run_2ways_test(bachelor_degree['writing_score'],master_degree['writing_score'])\n",
    "    print('master degree is '+('good than 'if math_test else 'similar with'  )+'bachelor degree in math ')\n",
    "    print('master degree is '+('good than 'if writing_test else 'similar with '  )+'bachelor degree in writing ')\n",
    "    print('master degree is '+('good than 'if redaing_test else 'similar with '  )+'bachelor degree in reading ')\n",
    "    print()\n",
    "    \n",
    "    print('associate degree vs some college:')\n",
    "    math_test=run_2ways_test(ass_degree['math_score'],somme_college['math_score'])\n",
    "    writing_test=run_2ways_test(ass_degree['reading_score'],somme_college['reading_score'])\n",
    "    redaing_test=run_2ways_test(ass_degree['writing_score'],somme_college['writing_score'])\n",
    "    print('associate degree is '+('good than 'if math_test else 'similar with'  )+'some college in math ')\n",
    "    print('associate degree is '+('good than 'if writing_test else 'similar with '  )+'some college in writing ')\n",
    "    print('associate degree is '+('good than 'if redaing_test else 'similar with '  )+'some college in reading ')\n",
    "    print()\n",
    "    \n",
    "    print('some high school vs high school:')\n",
    "    math_test=run_2ways_test(high_school['math_score'],somme_high_school['math_score'])\n",
    "    writing_test=run_2ways_test(high_school['reading_score'],somme_high_school['reading_score'])\n",
    "    redaing_test=run_2ways_test(high_school['writing_score'],somme_high_school['writing_score'])\n",
    "    print('some high school is '+('good than 'if math_test else 'similar with '  )+'high school in math ')\n",
    "    print('some high school is '+('good than 'if writing_test else 'similar with '  )+'high school in writing ')\n",
    "    print('some high school is '+('good than 'if redaing_test else 'similar with '  )+'high school in reading ')\n",
    "    print()\n",
    "    \n",
    "    print()\n",
    "    print('---------Running  one-ways ANOVA test (black box test):----------')\n",
    "    print()\n",
    "    print('---------race_ethnicity test---------')\n",
    "    print()\n",
    "    \n",
    "    f,p =stats.f_oneway(group_a, group_b, group_c, group_d ,group_e)\n",
    "    dic={'scores':principal_columns, 'F values':f, 'P values':p, 'it\\'s ok':f>p}\n",
    "    print(pd.DataFrame(dic))\n",
    "    print()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "In this module we gonna be using RandomForestClassifier to predict scores and to classify features importance.\n",
    "\n",
    "*   Transform categorical variable into numeric values using OneHotEncoder/OrdinalEncoder\n",
    "I have OneHotEncoder because it create a binary columns for each category in all features as result we end up with 17 columns of true/false like, 0 for false and 1 for true, thus we can't see which features are more imortant.\n",
    "*   Devide  dataset into two subdatasets (80/20 %) one for training the model and other for testing.\n",
    "*   Perfom prediction \n",
    "*   Find out features importance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Module Machine learning RandomForestClassifier\n",
    "\"\"\"\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 8)\n",
    "pd.set_option('display.width', 500)\n",
    "\n",
    "def main():\n",
    "    init_ml()\n",
    "    start_ml()\n",
    "    \n",
    "def start_ml():\n",
    "    print('Machine learning is warming up\\n')\n",
    "    print('================================================')\n",
    "    \n",
    "    task = input('Please type 1 for Prediction or 2 Features importance and hit enter key ↲')\n",
    "    if task == '2': # task is features importance\n",
    "        features_importance()\n",
    "        return\n",
    "    \n",
    "    elif task == '1': # task is prediction\n",
    "        npt = input('Enter your sample as array of shape (n row of 5 features) or press enter to run sample test data :')\n",
    "        \n",
    "        if (npt == 'exit'):\n",
    "            return\n",
    "        \n",
    "        elif ((npt is None ) or (len(npt)==0)):# If no data, we use a x_test samples\n",
    "            init_ml()\n",
    "            for t in targets:\n",
    "                predict(ftrs=None, target=t)\n",
    "            return\n",
    "       \n",
    "        elif len(npt)!=5: # prediction for user's data\n",
    "                print('Not correct input, expected input.\\n'.joint(targets))\n",
    "                return\n",
    "        else :\n",
    "            npt = np.array(npt.split(','))\n",
    "            npt = npt.reshape(1,5)\n",
    "            data = (pd.DataFrame(npt))\n",
    "            init_ml()\n",
    "            for t in targets:\n",
    "                predict(ftrs=data,target=t)\n",
    "    \n",
    "    else:# no task \n",
    "        print('sorry I can''t understand you.')\n",
    "        return      \n",
    "        \n",
    "    \n",
    "def init_ml() :\n",
    "    # Set random seed, so it start from 0\n",
    "    np.random.seed(0)\n",
    "    global targets    \n",
    "    targets = ds[['math_score','reading_score','writing_score']]\n",
    "    #split dataset \n",
    "    global x_train, x_test, y_train, y_test\n",
    "    x_train, x_test, y_train, y_test = train_test_split(ds, targets, test_size=0.2, random_state =0)\n",
    "    # preparing features\n",
    "    gender=x_train['gender'].unique()\n",
    "    race_ethnicity=x_train['race_ethnicity'].unique()\n",
    "    parental_level_of_education=x_train['parental_level_of_education'].unique()\n",
    "    lunch=x_train['lunch'].unique()\n",
    "    test_preparation_course=x_train['test_preparation_course'].unique()\n",
    "    #transforming features values from string to numeric\n",
    "    #ohe=OneHotEncoder(categories=[gender,race_ethnicity,parental_level_of_education,lunch,test_preparation_course])\n",
    "    global oe\n",
    "    oe=OrdinalEncoder(categories=[gender,race_ethnicity,parental_level_of_education,lunch,test_preparation_course])\n",
    "    global train_ds\n",
    "    global test_ds\n",
    "    train_ds = x_train[['gender','race_ethnicity','parental_level_of_education','lunch','test_preparation_course']]\n",
    "    test_ds=x_test[['gender','race_ethnicity','parental_level_of_education','lunch','test_preparation_course']]\n",
    "  \n",
    "    #ohe.fit(cat_ds)\n",
    "    oe.fit(train_ds)\n",
    "    #OneHotEncoder()\n",
    "    OrdinalEncoder()\n",
    "    #features = ohe.transform(train_ds).toarray()\n",
    "    global features\n",
    "    features = oe.transform(train_ds)\n",
    "    #don't use this encoder because it generates more new columns, (see note in introduction)\n",
    "    #trfm=ohe.transform([['male','group E','some high school','standard','none']]).toarray()\n",
    "    \n",
    "    # Training algorithms\n",
    "    global clf_rf\n",
    "    global clf_svc\n",
    "    # initiate random forest algo.\n",
    "    clf_rf=RandomForestClassifier(n_jobs=2, random_state=0)\n",
    "    # initiate support vector machine algo. (it does not suport multi-class output)\n",
    "    clf_svc = svm.SVC(kernel='linear', C=1, random_state=0)\n",
    "   \n",
    "    \n",
    "def features_importance():\n",
    "    print('-----------------------------------')\n",
    "    clf_rf=RandomForestClassifier(n_jobs=2, random_state=0)\n",
    "    clf_rf.fit(np.asarray(features), y_train)\n",
    "    \n",
    "    features_importance=clf_rf.feature_importances_\n",
    "    fi_df=pd.DataFrame(features_importance.reshape(1,5), columns=['gender','race_ethnicity','parental_level_of_education','lunch','test_preparation_course'])\n",
    "\n",
    "    print('Features importance classification using Random forest classifier')\n",
    "    print\n",
    "    print(fi_df)\n",
    "    print()\n",
    "    fi_df.plot(kind='bar', xlabel='Features', ylabel='Importance level' ,figsize=[10,10],)\n",
    "    \n",
    "def predict(ftrs = None, target=None):\n",
    "    print()    \n",
    "    clf_rf.fit(np.asarray(features), y_train[target])\n",
    "    clf_svc.fit(np.asarray(features),y_train[target])\n",
    "    \"\"\"\n",
    "    This is a sample to predict scores \n",
    "    trfm=oe.transform([['male','group E','some high school','standard','none'],\\\n",
    "                   ['female','group E','some high school','standard','none'],\\\n",
    "                   ['male','group C','some high school','standard','none'],\\\n",
    "                   ['female','group C','some high school','standard','none']])\n",
    "    \"\"\"\n",
    "    global rows_count\n",
    "    rows_count=200\n",
    "    global trfm\n",
    "    if((ftrs is None) or (len(ftrs)==0)):\n",
    "        trfm=oe.transform(test_ds.head(rows_count))\n",
    "    else:\n",
    "        rows_count=len(ftrs.index)\n",
    "        trfm=oe.transform(ftrs)\n",
    "        \n",
    "    pred_df=clf_rf.predict(trfm)\n",
    "    #pred_df=pd.DataFrame(pred_df.reshape(rows_count,3),columns=['math_score','reading_score','writing_score'])\n",
    "    print()\n",
    "    print('prediction for '+target +' using random forest classifier ')\n",
    "    print(pred_df)\n",
    "    alogo_pefromance_score(target)\n",
    "    print('prediction for '+target +' students using svm support vector machine ')\n",
    "    print()\n",
    "    print(clf_svc.predict(trfm))\n",
    "    alogo_pefromance_score(target)\n",
    "    print()\n",
    "    \n",
    "def alogo_pefromance_score(target=None):\n",
    "    if target is None:\n",
    "        prtin('Not target specified')\n",
    "        return\n",
    "    rf_score = clf_rf.score(trfm, y_test[target].head(rows_count))\n",
    "    svc_score = clf_svc.score(trfm,y_test[target].head(rows_count))\n",
    "    print()\n",
    "    print('Algorithms performance scores:')\n",
    "    print()\n",
    "    dic={'algorithm':['Random_Forest_Classifier','Support_Vector_Machine'], \\\n",
    "         'Score':[rf_score,svc_score]}\n",
    "    print(pd.DataFrame(dic))\n",
    "    print()\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    main()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(cross_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "l6o_1GzruGqT",
    "rpp45iLa2Gc6"
   ],
   "name": "studentBAP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
